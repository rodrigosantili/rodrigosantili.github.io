<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Rodrigo Santili Sgarioni - Data Platform Manager</title>
    <meta name="description" content="Executivo de Dados com mais de 15 anos de experiência liderando plataformas analíticas, governança de dados e times técnicos de alta performance.">
    <meta name="keywords" content="Data Platform Manager, Data Engineering, DataOps, Snowflake, Databricks, AWS, Liderança em Dados">
    <meta name="author" content="Rodrigo Santili Sgarioni">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://rodrigosantili.github.io/">
    <meta property="og:title" content="Rodrigo Santili Sgarioni - Data Platform Manager">
    <meta property="og:description" content="Executivo de Dados com mais de 15 anos de experiência liderando plataformas analíticas e times técnicos.">
    <meta property="og:image" content="https://rodrigosantili.github.io/assets/images/profile-og.jpg">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="https://rodrigosantili.github.io/">
    <meta property="twitter:title" content="Rodrigo Santili Sgarioni - Data Platform Manager">
    <meta property="twitter:description" content="Executivo de Dados com mais de 15 anos de experiência liderando plataformas analíticas e times técnicos.">
    <meta property="twitter:image" content="https://rodrigosantili.github.io/assets/images/profile-og.jpg">

    <!-- Favicon -->
    <link rel="icon" type="image/x-icon" href="assets/images/favicon.ico">
    
    <!-- CSS -->
    <link rel="stylesheet" href="assets/css/style.css">
    
    <!-- Font Awesome -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    
    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=GA_MEASUREMENT_ID"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'GA_MEASUREMENT_ID');
    </script>
</head>
<body>
    <!-- Skip to content link -->
    <a href="#main-content" class="skip-link">Pular para o conteúdo principal</a>
    
    <!-- Loading -->
    <div class="loading" style="position: fixed; top: 50%; left: 50%; transform: translate(-50%, -50%); z-index: 9999;"></div>

    <!-- Navegação -->
    <nav class="navbar">
        <div class="navbar-container">
            <a href="#" class="navbar-brand">
                <i class="fas fa-chart-line"></i>
                Rodrigo Santili
            </a>
            <ul class="navbar-menu">
                <li><a href="#sobre" class="active">Sobre</a></li>
                <li><a href="#experiencia">Experiência</a></li>
                <li><a href="#competencias">Competências</a></li>
                <li><a href="#habilidades">Stack</a></li>
                <li><a href="#projetos">Projetos</a></li>
                <li><a href="#formacao">Formação</a></li>
                <li><a href="#idiomas">Idiomas</a></li>
                <li><a href="#objetivos">Objetivos</a></li>
            </ul>
            <button id="dark-mode-toggle" class="dark-mode-toggle" aria-label="Alternar modo escuro">
                <i class="fas fa-moon"></i>
            </button>
        </div>
    </nav>

    <!-- Header -->
    <header class="header">
        <div class="header-content">
            <div class="container">
                <div class="header-layout">
                    <!-- Conteúdo à esquerda -->
                    <div class="header-left">
                        <h1>Rodrigo Santili Sgarioni</h1>
                        
                        <p class="subtitle">Data Platform Manager | Data Engineering Manager | BI Manager | Data Architect | Data Engineering | DataOps</p>
                        <p class="subtitle-secondary">Snowflake • Databricks • Kafka • AWS/GCP • Real-time Pipelines • ML Engineering</p>
                        
                        <div class="contact-info">
                            <a href="mailto:rssgarioni@gmail.com" class="contact-item">
                                <i class="fas fa-envelope"></i>
                            </a>
                            <a href="https://www.linkedin.com/in/rodrigo-santili-sgarioni-48004330" target="_blank" class="contact-item">
                                <i class="fab fa-linkedin"></i>
                            </a>
                            <a href="https://github.com/rodrigosantili" target="_blank" class="contact-item">
                                <i class="fab fa-github"></i>
                            </a>
                        </div>
                    </div>
                    
                    <!-- Foto à direita -->
                    <div class="header-right">
                        <img src="assets/images/profile-photo.jpg" alt="Rodrigo Santili" class="profile-photo">
                    </div>
                </div>
            </div>
        </div>
    </header>

    <br>
    <main id="main-content" class="container">
        <!-- Sobre Mim -->
        <section class="section" id="sobre">
            <h2 class="section-title">
                <i class="fas fa-user"></i>
                Sobre Mim
            </h2>

                <div class="profile-content">
                        <p>Desde o início da minha carreira, fui movido por um propósito claro: <strong>transformar dados brutos em decisões inteligentes</strong> que impulsionam o negócio. Com mais de 15 anos de experiência na área de dados, trilhei um caminho sólido desde ambientes críticos de banco de dados transacionais até liderar grandes iniciativas de Arquitetura e Engenharia de dados com tecnologias em Cloud como AWS e GCP e plataformas modernas como Snowflake e Databricks.</p>
                        
                        <p>Atuei como <strong>Data Architect e Data Platform Manager</strong>, liderando times técnicos e multidisciplinares na implementação de Data Lakes, Data Warehouses, pipelines de ETL/ELT e arquiteturas escaláveis e seguras. Ao longo da jornada, fui responsável por estruturar plataformas robustas, integrar sistemas de streaming em tempo real, e entregar soluções de alto desempenho alinhadas aos objetivos estratégicos da empresa.</p>
                        
                        <p>Sou formado em <strong>Banco de Dados pela FIAP</strong>, com <strong>MBA em Big Data</strong> com foco em Data Science, e atualmente curso <strong>pós-graduação em Machine Learning Engineering</strong>. Minha atuação combina visão de negócio, profundidade técnica e liderança de equipes, com domínio de DataOps, governança de dados, automação de pipelines, e integração de sistemas críticos em ambientes de missão crítica.</p>
                        
                        <p>Além das competências técnicas, me destaco por minha capacidade de <strong>construir pontes entre times de tecnologia e áreas de negócio</strong>, tornando-me um facilitador entre a complexidade técnica e as demandas estratégicas. Fluente em inglês técnico e com conhecimento em espanhol.</p>
                        
                        <p>Se você busca um profissional com <strong>visão estratégica</strong>, <strong>mindset data-driven</strong> e capacidade de entregar valor através de <strong>soluções de dados modernas</strong>, vamos conversar.</p>
                    </div>
                <!-- Estatísticas integradas -->
                <!-- <div class="profile-stats">
                    <div class="profile-stat">
                        <span class="profile-stat-number">15+</span>
                        <div class="profile-stat-label">Anos de Experiência</div>
                    </div>
                    <div class="profile-stat">
                        <span class="profile-stat-number">10+</span>
                        <div class="profile-stat-label">Empresas Atendidas</div>
                    </div>
                    <div class="profile-stat">
                        <span class="profile-stat-number">15+</span>
                        <div class="profile-stat-label">Pessoas Lideradas</div>
                    </div>
                    <div class="profile-stat">
                        <span class="profile-stat-number">50+</span>
                        <div class="profile-stat-label">Projetos Concluídos</div>
                    </div>
                </div>
            </div> -->


        </section>



        <!-- Experiência Profissional -->
        <section class="section" id="experiencia">
            <h2 class="section-title">
                <i class="fas fa-briefcase"></i>
                Experiência Profissional
            </h2>
            
            <div class="experience-item">
                <div class="experience-title">Data Architect / Data Engineering / DataOps</div>
                <div class="experience-company">V8.TECH</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 02/2022 - Presente | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Liderança técnica</strong> em projetos estratégicos de arquitetura de dados com foco em plataformas modernas (Snowflake, Databricks)</li>
                        <li><strong>Arquiteto responsável</strong> em projetos de implementação de Databricks, focando em performance de processamento distribuído, integração com pipelines ETL/ELT e automação de data lakes</li>
                        <li><strong>Participação ativa</strong> na estruturação e apoio técnico às frentes comerciais da empresa, contribuindo para a concepção de ofertas e estratégias de venda consultiva de soluções analíticas</li>
                        <li><strong>Implantação de pipelines</strong> de dados em tempo real e arquitetura de eventos utilizando Confluent (Kafka), permitindo streaming analytics e redução do tempo de ingestão e transformação de dados</li>
                        <li><strong>Condução de projetos</strong> de modernização de ambientes legados, com migração on-premise → cloud (AWS), priorizando escalabilidade, segurança, custo e governança</li>
                    </ul>
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-title">Data Platform Manager</div>
                <div class="experience-company">GRUPO SBF</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 12/2020 - 01/2022 | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Estruturou e liderou</strong> o time de arquitetura de dados da companhia, sendo responsável por todo o ecossistema analítico das unidades de negócio do grupo</li>
                        <li><strong>Liderou a modernização</strong> da plataforma de dados com migração para cloud (AWS), definindo arquitetura escalável, segura e resiliente</li>
                        <li><strong>Estabeleceu diretrizes</strong> de governança de dados, promovendo padronização de pipelines, catálogo de dados e definição de políticas de qualidade e compliance</li>
                        <li><strong>Coordenou o alinhamento</strong> estratégico entre áreas técnicas e executivas (C-level), assegurando aderência das iniciativas de dados aos objetivos corporativos</li>
                        <li><strong>Implementou soluções</strong> de Data Lake e Data Warehouse modernos com Snowflake e AWS</li>
                    </ul>
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-title">Data Platform Manager</div>
                <div class="experience-company">CENTAURO</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 06/2018 - 11/2020 | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Responsável pela concepção</strong> e execução da nova arquitetura de dados da empresa, incluindo a criação de um Data Lake corporativo e modernização do DW</li>
                        <li><strong>Conduziu projetos</strong> de integração entre canais físicos e digitais, suportando a jornada omnichannel com dados confiáveis e em tempo real</li>
                        <li><strong>Implantou pipelines</strong> de dados baseados em cloud, priorizando escalabilidade, observabilidade e custos</li>
                        <li><strong>Liderou equipe técnica</strong> multidisciplinar (engenharia, BI e arquitetura), fomentando cultura orientada a dados e entregas ágeis</li>
                    </ul>
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-title">BI Manager</div>
                <div class="experience-company">CENTAURO</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 06/2018 - 12/2020 | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Liderança da área</strong> de Business Intelligence, com foco em entrega de análises estratégicas e dashboards executivos</li>
                        <li><strong>Implementou processos</strong> de governança de dados e padronização de visualizações, garantindo qualidade e consistência nas decisões</li>
                    </ul>
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-title">Database Admin Manager</div>
                <div class="experience-company">CENTAURO</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 01/2013 - 05/2018 | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Gerenciou time</strong> de administradores de banco de dados, assegurando disponibilidade, performance e segurança em ambientes críticos</li>
                        <li><strong>Implantou planos</strong> de contingência e soluções de alta disponibilidade, minimizando downtime e riscos operacionais</li>
                    </ul>
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-title">Senior DBA</div>
                <div class="experience-company">NOVA PONTOCOM (GPA)</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 05/2011 - 12/2012 | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Especialista em performance tuning</strong>, modelagem de dados e automação de processos em ambientes de missão crítica</li>
                        <li><strong>Atuação próxima</strong> à equipe de desenvolvimento para otimização de arquitetura de dados e segurança da informação</li>
                    </ul>
                </div>
            </div>

            <div class="experience-item">
                <div class="experience-title">DBA Pleno</div>
                <div class="experience-company">UOL Diveo</div>
                <div class="experience-period">
                    <i class="fas fa-calendar"></i> 03/2008 - 12/2011 | 
                    <i class="fas fa-map-marker-alt"></i> São Paulo, Brasil
                </div>
                <div class="experience-description">
                    <ul>
                        <li><strong>Administração e sustentação</strong> de ambientes Oracle, SQL Server e MySQL com foco em disponibilidade, integridade e desempenho</li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Competências -->
        <section class="section" id="competencias">
            <h2 class="section-title">
                <i class="fas fa-star"></i>
                Competências
            </h2>
            <div class="grid">
                <div class="card">
                    <h3><i class="fas fa-database"></i> Data Platform Management</h3>
                    <ul>
                        <li>Liderança de plataformas de dados</li>
                        <li>Arquitetura de Data Lakes e Data Warehouses</li>
                        <li>Implementação de Snowflake e Databricks</li>
                        <li>Governança e qualidade de dados</li>
                    </ul>
                </div>
                <div class="card">
                    <h3><i class="fas fa-cogs"></i> Data Engineering</h3>
                    <ul>
                        <li>Arquitetura e desenvolvimento de pipelines</li>
                        <li>ETL/ELT e processamento de dados</li>
                        <li>Real-time data processing</li>
                        <li>Performance tuning e otimização</li>
                    </ul>
                </div>
                <div class="card">
                    <h3><i class="fas fa-sync"></i> DataOps</h3>
                    <ul>
                        <li>Automação e governança de dados</li>
                        <li>CI/CD para pipelines de dados</li>
                        <li>Monitoramento e observabilidade</li>
                        <li>Práticas DevOps aplicadas a dados</li>
                    </ul>
                </div>
                <div class="card">
                    <h3><i class="fas fa-cloud"></i> Cloud Architecture</h3>
                    <ul>
                        <li>AWS, GCP e Azure</li>
                        <li>Arquiteturas serverless</li>
                        <li>Microservices e containers</li>
                        <li>Segurança e compliance</li>
                    </ul>
                </div>
                <div class="card">
                    <h3><i class="fas fa-user-tie"></i> Team Leadership</h3>
                    <ul>
                        <li>Liderança de equipes multidisciplinares (20 pessoas)</li>
                        <li>Desenvolvimento de talentos e mentoria técnica</li>
                        <li>Cultura de inovação e aprendizado contínuo</li>
                        <li>Gestão de performance e feedback</li>
                    </ul>
                </div>
                <div class="card">
                    <h3><i class="fas fa-chart-line"></i> Estratégia e Governança</h3>
                    <ul>
                        <li>Definição de roadmaps estratégicos de dados</li>
                        <li>Implementação de frameworks de governança</li>
                        <li>Alinhamento com objetivos de negócio (C-level)</li>
                        <li>Políticas de qualidade e compliance</li>
                    </ul>
                </div>
            </div>
            <br>
        </section>

        <!-- Stack Tecnológico -->
        <section class="section" id="habilidades">
            <h2 class="section-title">
                <i class="fas fa-code"></i>
                Stack Tecnológico
            </h2>
            <div class="skills-grid">
                <div class="skill-category">
                    <h4><i class="fas fa-cloud"></i> Cloud Platforms</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-cloud-platforms">AWS</span></li>
                        <li><span class="badge badge-cloud-platforms">Google Cloud</span></li>
                        <li><span class="badge badge-cloud-platforms">Azure</span></li>
                        <li><span class="badge badge-cloud-platforms">FinOps</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-database"></i> Modern Data Platforms</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-modern-data-platforms">Snowflake</span></li>
                        <li><span class="badge badge-modern-data-platforms">Databricks</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-sync"></i> ETL/ELT & Orchestration</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-etl-orchestration">Airflow</span></li>
                        <li><span class="badge badge-etl-orchestration">Airbyte</span></li>
                        <li><span class="badge badge-etl-orchestration">dbt</span></li>
                        <li><span class="badge badge-etl-orchestration">Talend</span></li>
                        <li><span class="badge badge-etl-orchestration">Confluent Kafka</span></li>
                        <li><span class="badge badge-etl-orchestration">Integration Services</span></li>
                        <li><span class="badge badge-etl-orchestration">Oracle ODI</span></li>
                        <li><span class="badge badge-etl-orchestration">Fivetran</span></li>
                        <li><span class="badge badge-etl-orchestration">NIFI</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-chart-pie"></i> Analytics & Visualization</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-analytics-visualization">Power BI</span></li>
                        <li><span class="badge badge-analytics-visualization">Tableau</span></li>
                        <li><span class="badge badge-analytics-visualization">Apache Superset</span></li>
                        <li><span class="badge badge-analytics-visualization">Streamlit</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-laptop-code"></i> Programming & Languages</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-programming-languages">Python</span></li>
                        <li><span class="badge badge-programming-languages">Spark</span></li>
                        <li><span class="badge badge-programming-languages">SQL</span></li>
                        <li><span class="badge badge-programming-languages">PL/SQL</span></li>
                        <li><span class="badge badge-programming-languages">Transact-SQL</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-cogs"></i> Architecture & Tools</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-architecture-tools">Data Lake</span></li>
                        <li><span class="badge badge-architecture-tools">Data Warehouse</span></li>
                        <li><span class="badge badge-architecture-tools">Data Mesh</span></li>
                        <li><span class="badge badge-architecture-tools">Microservices</span></li>
                        <li><span class="badge badge-architecture-tools">Event-Driven</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-brain"></i> AI & Machine Learning Engineering</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-ai-machine-learning">Machine Learning</span></li>
                        <li><span class="badge badge-ai-machine-learning">Data Science</span></li>
                        <li><span class="badge badge-ai-machine-learning">MLOps</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-database"></i> Databases</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-databases">Oracle</span></li>
                        <li><span class="badge badge-databases">SQL Server</span></li>
                        <li><span class="badge badge-databases">Informix</span></li>
                        <li><span class="badge badge-databases">MongoDB</span></li>
                        <li><span class="badge badge-databases">MySQL</span></li>
                        <li><span class="badge badge-databases">PostgreSQL</span></li>
                    </ul>
                </div>
                <div class="skill-category">
                    <h4><i class="fas fa-cloud"></i> Infrastructure as Code & DevOps</h4>
                    <ul class="skill-list">
                        <li><span class="badge badge-iac-devops">Terraform</span></li>
                        <li><span class="badge badge-iac-devops">Docker</span></li>
                        <li><span class="badge badge-iac-devops">Kubernetes</span></li>
                        <li><span class="badge badge-iac-devops">Jenkins</span></li>
                        <li><span class="badge badge-iac-devops">Git</span></li>
                        <li><span class="badge badge-iac-devops">GitHub</span></li>
                        <li><span class="badge badge-iac-devops">GitLab</span></li>
                        <li><span class="badge badge-iac-devops">CI/CD</span></li>
                        <li><span class="badge badge-iac-devops">Azure DevOps</span></li>
                    </ul>
                </div>
            </div>
        </section>

        <!-- Projetos Destacados -->
        <section class="section" id="projetos">
            <h2 class="section-title">
                <i class="fas fa-project-diagram"></i>
                Projetos Destacados
            </h2>
            <div class="grid">
                <div class="project-card" data-category="modernization">
                    <div class="project-content">
                        <h3 class="project-title">
                            Modernização de Plataforma de Dados
                            <div class="project-role leadership">LIDERANÇA</div> 
                            <div class="project-role architecture">ARQUITETURA</div>
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">Centauro</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A Centauro enfrentava desafios críticos com sua infraestrutura on-premise: custos operacionais elevados, limitações de escalabilidade e dificuldades para manter alta disponibilidade. Os dados de e-commerce e loja física estavam em ambientes de BI separados, impossibilitando análises integradas entre os canais. A plataforma legada (Oracle + SQL Server) não conseguia atender às demandas crescentes de dados e análises em tempo real.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Liderei o projeto de modernização, desenhei a arquitetura completa e participei da implementação junto com o time técnico.</p>
                                <p>Lideramos a migração completa para AWS, implementando uma arquitetura moderna com Data Lake e Data Warehouse. Desenvolvemos pipelines ETL/ELT automatizados, estabelecemos governança de dados robusta e criamos sistema de monitoramento em tempo real para otimização contínua.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A modernização resultou em <strong>governança de dados robusta</strong>, <strong>dados atualizados near real-time</strong> e <strong>escalabilidade automática</strong>. A plataforma agora suporta análises em tempo real, impulsionando decisões estratégicas mais ágeis. Os dados de loja física e e-commerce no mesmo ambiente possibilitam análises integradas e insights holísticos do negócio.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-databases">Oracle</span>
                            <span class="badge badge-databases">SQL Server</span>
                            <span class="badge badge-etl-orchestration">Talend</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="migration">
                    <div class="project-content">
                        <h3 class="project-title">
                            Migração da Plataforma de Dados da AWS para GCP
                            <div class="project-role leadership">LIDERANÇA</div>
                            <div class="project-role architecture">ARQUITETURA</div>
                        </h3>
                        <div class="project-client">Centauro</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A GCP fez uma proposta agressiva em relação ao preço do dólar onde teríamos uma grande redução de custos em relação à AWS. A empresa precisava migrar toda a infraestrutura de dados para aproveitar essa oportunidade de economia, mantendo a performance e escalabilidade da plataforma existente.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Liderei a criação da nova arquitetura da GCP, garantindo governança, plataforma escalável e otimização de custos.</p>
                                <p>Desenhei e implementei uma arquitetura moderna na GCP com BigQuery, Dataflow e Cloud Storage. Criamos pipelines otimizados, separação clara entre ambientes (DEV, QAS, PROD), implementamos governança de dados robusta e estabelecemos monitoramento avançado de custos e performance.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A migração resultou em <strong>redução de 40% nos custos</strong> do projeto e conseguimos implementar ambientes de DEV e QAS separados. Os pipelines ficaram <strong>mais rápidos</strong>, com separação eficiente entre processamento real-time e batch. A nova arquitetura proporcionou <strong>maior escalabilidade</strong> e <strong>melhor governança</strong> de dados.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-cloud-platforms">Google Cloud</span>
                            <span class="badge badge-etl-orchestration">Dataflow</span>
                            <span class="badge badge-databases">BigQuery</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="realtime">
                    <div class="project-content">
                        <h3 class="project-title">
                            Arquitetura de Eventos em Tempo Real
                            <div class="project-role leadership">LIDERANÇA</div>
                        </h3>
                        <div class="project-client">Centauro</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A Centauro precisava processar grandes volumes de dados em tempo real para decisões estratégicas ágeis. O sistema legado não conseguia lidar com a velocidade e volume de eventos gerados pelos canais digitais, causando atrasos críticos na tomada de decisões e perda de oportunidades de negócio.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Liderei o projeto de implementação da arquitetura de eventos distribuídos.</p>
                                <p>Implementamos arquitetura de eventos distribuídos com Confluent (Kafka) para streaming de dados em tempo real. Desenvolvemos soluções de Data Mesh, automatizamos pipelines ETL/ELT e criamos sistema de monitoramento em tempo real para processamento eficiente de dados.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A nova arquitetura resultou em <strong>processamento ultra-rápido</strong> de eventos, <strong>eliminação de gargalos</strong> de latência e <strong>capacidade de processar milhões de eventos por segundo</strong>. Agora a empresa pode tomar decisões em tempo real baseadas em dados atualizados, impulsionando a agilidade estratégica e capturando oportunidades de negócio que antes eram perdidas.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-etl-orchestration">Confluent Kafka</span>
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-architecture-tools">Data Mesh</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="omnichannel">
                    <div class="project-content">
                        <h3 class="project-title">
                            Jornada Omnichannel
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">Centauro</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A Centauro precisava integrar o estoque entre loja física e e-commerce, permitindo que ambos os canais enxergassem o estoque um do outro. A falta de visibilidade cruzada impedia que clientes do e-commerce vissem o estoque da loja física mais próxima e vice-versa, limitando as opções de compra e entrega.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Implementei a solução técnica para unificação de estoque entre os sistemas.</p>
                                <p>Desenvolvemos solução completa para unificação de estoque entre loja física (IBM Informix), e-commerce (SQL Server) e sistema central (SAP). Implementamos sincronização automática de dados de estoque entre os sistemas, criando um sistema único de verdade para o estoque em todos os canais.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A solução permitiu que <strong>clientes do e-commerce vissem o estoque da loja física mais próxima</strong> e <strong>clientes de loja física vissem o estoque do e-commerce</strong>. Além disso, habilitou a <strong>opção de entrega direta da loja física mais próxima do cliente</strong>, melhorando significativamente a experiência omnichannel e aumentando as opções de compra disponíveis. O projeto também <strong>reduziu custos de logística</strong> através da otimização das rotas de entrega.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-databases">Oracle</span>
                            <span class="badge badge-databases">SQL Server</span>
                            <span class="badge badge-databases">Informix</span>
                            <span class="badge badge-databases">SAP</span>
                        </div>
                    </div>
                </div>
                <div class="project-card" data-category="security">
                    <div class="project-content">
                        <h3 class="project-title">
                            Projeto de Mascaramento e Desmascaramento de Dados
                            <div class="project-role architecture">ARQUITETURA</div>
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">SolFacil</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>Os dados que vinham dos ambientes transacionais não eram mascarados, resultando em dados sensíveis expostos em todas as camadas do Data Lake. Isso criava um risco crítico de vazamento de dados sensíveis, violando políticas de privacidade e regulamentações como LGPD.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Desenhei a arquitetura de segurança e implementei o sistema de mascaramento.</p>
                                <p>Desenvolvemos sistema de mascaramento de dados usando tokens entre as camadas Silver e Gold do Data Lake. Implementamos função Lambda no Redshift para descriptografia seletiva, criando controle granular de acesso baseado em permissões e contexto de uso.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A solução resultou em <strong>dados totalmente mascarados nas camadas Silver e Gold</strong>. Como o mascaramento era por token, possibilitava a descriptografia através de UDF no Redshift para consultar o dado original quando necessário, mantendo a segurança sem comprometer a funcionalidade.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-programming-languages">Python</span>
                            <span class="badge badge-programming-languages">Spark</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="performance">
                    <div class="project-content">
                        <h3 class="project-title">
                            CLI para Performance e Tuning "dbt-perf"
                            <div class="project-role architecture">ARQUITETURA</div>
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">SolFacil</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A SolFacil enfrentava problemas constantes com performance de modelos DBT em produção. Deploys quebrados, queries lentas e falta de padronização no processo de validação causavam retrabalho e impactos na produtividade da equipe de dados.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Desenhei a arquitetura da ferramenta e implementei a CLI completa.</p>
                                <p>Desenvolvemos a CLI "dbt-perf" com 3 camadas de validação: validação de erros nos modelos DBT, análise de performance no Redshift com explain de queries e sistema de score para aprovação/reprovação automática do deploy dos modelos.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A ferramenta resultou em <strong>redução significativa nos deploys quebrados</strong>, <strong>melhoria na performance</strong> dos modelos e <strong>padronização completa</strong> do processo de deploy. O Redshift também <strong>parou de ter problemas de performance constantes</strong> após a implementação. A equipe agora tem confiança total nos deploys e um processo automatizado de validação que garante qualidade antes da produção.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-etl-orchestration">dbt</span>
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-programming-languages">Python</span>
                            <span class="badge badge-programming-languages">CLI</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="distribution">
                    <div class="project-content">
                        <h3 class="project-title">
                            Distribuição de Carga - AWS Redshift DataShare
                            <div class="project-role architecture">ARQUITETURA</div>
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">SolFacil</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A SolFacil enfrentava conflitos de recursos no Redshift entre diferentes workloads (ETL, BI e aplicações). Queries lentas, timeouts e falta de isolamento entre ambientes causavam impactos na produtividade e frustração dos usuários.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Desenhei a arquitetura de distribuição de carga e implementei o DataShare.</p>
                                <p>Criamos DataShare no AWS Redshift compartilhado com 3 clusters para distribuição de carga por área/aplicação. Separamos workloads entre ETL, relatórios de BI e aplicações de negócio, eliminando concorrência de recursos.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>A solução resultou em <strong>eliminação completa dos conflitos</strong> de recursos, <strong>melhoria significativa na performance</strong> das queries e <strong>isolamento completo</strong> entre ambientes. Cada área agora tem seu próprio cluster otimizado, garantindo melhor utilização dos recursos e estabilidade operacional.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-programming-languages">SQL</span>
                            <span class="badge badge-iac-devops">Terraform</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="finops">
                    <div class="project-content">
                        <h3 class="project-title">
                            Projeto de FinOps - Databricks e AWS
                            <div class="project-role architecture">ARQUITETURA</div>
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">Mills</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A Mills enfrentava custos cloud descontrolados e falta de visibilidade sobre gastos com Databricks e AWS. Sem governança financeira, os custos cresciam exponencialmente, impactando a rentabilidade e dificultando o planejamento orçamentário.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Desenhei a arquitetura de FinOps e implementei o sistema de monitoramento de custos.</p>
                                <p>Implementamos estratégias avançadas de FinOps para Databricks e AWS, incluindo otimização de custos com monitoramento avançado, governança financeira com alocação de custos por projeto, automação de relatórios e alertas inteligentes. Unificamos os dados de custos entre os dois ambientes, dando visibilidade mais granular dos custos por usuário do Databricks.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>O projeto resultou em <strong>visibilidade granular dos custos de Databricks</strong>, permitindo análise por cluster e até mesmo por usuário. A empresa agora tem controle total sobre seus investimentos em tecnologia, com insights detalhados sobre o consumo de recursos.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-modern-data-platforms">Databricks</span>
                            <span class="badge badge-cloud-platforms">AWS</span>
                            <span class="badge badge-architecture-tools">FinOps</span>
                            <span class="badge badge-programming-languages">Python</span>
                        </div>
                    </div>
                </div>

                <div class="project-card" data-category="analytics">
                    <div class="project-content">
                        <h3 class="project-title">
                            Projeto de Integração e Analytics para Clientes
                            <div class="project-role architecture">ARQUITETURA</div>
                            <div class="project-role development">DESENVOLVIMENTO</div>
                        </h3>
                        <div class="project-client">Mills</div>
                        <div class="project-meta">
                            <span><i class="fas fa-map-marker-alt"></i> São Paulo, Brasil</span>
                        </div>
                        <hr class="project-divider">
                        <br>
                        <div class="project-story">
                            <div class="story-section">
                                <h4 class="story-title">Desafio</h4>
                                <p>A Mills tinha dados fragmentados entre 4 Business Units, impossibilitando análises holísticas de negócio. A falta de visão unificada impedia identificação de oportunidades de cross-sell, análise de churn e otimização de vendas entre as BUs.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Solução</h4>
                                <p><strong>Meu Papel:</strong> Implementei a integração dos dados e desenvolvimento dos dashboards de analytics.</p>
                                <p>Realizamos integração dos dados das 3 BUs faltantes no Data Lake (Databricks), processando através das camadas Bronze, Silver até Gold. Unificamos com dados da BU existente, criando visão consolidada e dashboards interativos para análise de negócio.</p>
                            </div>
                            
                            <div class="story-section">
                                <h4 class="story-title">Resultado</h4>
                                <p>O projeto resultou em <strong>visão unificada de 4 BUs</strong>, possibilitando análises de cross-sell, churn, vendas e muito mais. A empresa agora tem insights completos do negócio, com capacidade de análise preditiva e identificação de oportunidades entre as diferentes unidades de negócio.</p>
                            </div>
                        </div>
                        <div class="project-tech">
                            <span class="badge badge-modern-data-platforms">Databricks</span>
                            <span class="badge badge-programming-languages">SQL</span>
                            <span class="badge badge-programming-languages">Streamlit</span>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Formação e Certificações -->
        <section class="section" id="formacao">
            <h2 class="section-title">
                <i class="fas fa-graduation-cap"></i>
                Formação Acadêmica & Certificações
            </h2>
            <div class="grid">
                <div class="card">
                    <h3><i class="fas fa-university"></i> Formação Acadêmica</h3>
                    <div style="margin-bottom: 20px;">
                        <h4>MBA em Big Data e Data Science</h4>
                        <p><strong>Instituição:</strong> FIAP</p>
                        <p><strong>Período:</strong> 2018-2019</p>
                    </div>
                    <div style="margin-bottom: 20px;">
                        <h4>Tecnólogo em Banco de Dados</h4>
                        <p><strong>Instituição:</strong> FIAP</p>
                        <p><strong>Período:</strong> 2012</p>
                    </div>
                    <div>
                        <h4>Pós Graduação em Machine Learning Engineering</h4>
                        <p><strong>Instituição:</strong> FIAP</p>
                        <p><strong>Período:</strong> 2025</p>
                    </div>
                </div>
                <div class="card">
                    <h3><i class="fas fa-certificate"></i> Certificações</h3>
                    <div style="margin-bottom: 15px;">
                        <h4>Introduction to AI and Machine Learning on Google Cloud</h4>
                        <p><strong>Emissor:</strong> Google</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Snowflake Sales Professional Accreditation</h4>
                        <p><strong>Emissor:</strong> Snowflake</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Hands On Essentials - Data Lake</h4>
                        <p><strong>Emissor:</strong> Snowflake</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Hands On Essentials - Data Applications</h4>
                        <p><strong>Emissor:</strong> Snowflake</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Hands On Essentials - Data Sharing</h4>
                        <p><strong>Emissor:</strong> Snowflake</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Hands On Essentials - Data Warehouse</h4>
                        <p><strong>Emissor:</strong> Snowflake</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Databricks Data Engineer Foundations</h4>
                        <p><strong>Emissor:</strong> Databricks</p>
                    </div>
                    <div style="margin-bottom: 15px;">
                        <h4>Confluent Fundamentals</h4>
                        <p><strong>Emissor:</strong> Confluent</p>
                    </div>
                </div>
            </div>
        </section>

        <!-- Idiomas -->
        <section class="section" id="idiomas">
            <h2 class="section-title">
                <i class="fas fa-language"></i>
                Idiomas
            </h2>
            <div class="grid">
                <div class="card">
                    <h3>🇧🇷 Português</h3>
                    <p><strong>Nível:</strong> Nativo</p>
                    <p><strong>Proficiência:</strong> ⭐⭐⭐⭐⭐</p>
                </div>
                <div class="card">
                    <h3>🇺🇸 Inglês</h3>
                    <p><strong>Nível:</strong> Intermediário</p>
                    <p><strong>Proficiência:</strong> ⭐⭐⭐○○</p>
                    <p><strong>Detalhes:</strong> Leitura técnica e comunicação funcional</p>
                </div>
                <div class="card">
                    <h3>🇪🇸 Espanhol</h3>
                    <p><strong>Nível:</strong> Básico</p>
                    <p><strong>Proficiência:</strong> ⭐○○○○</p>
                    <p><strong>Detalhes:</strong> Leitura técnica e comunicação básica</p>
                </div>
            </div>
        </section>

        <!-- Objetivos Profissionais -->
        <section class="section" id="objetivos">
            <h2 class="section-title">
                <i class="fas fa-target"></i>
                Objetivos Profissionais
            </h2>
            <div class="grid">
                <div class="card">
                    <h3>Vagas de Interesse</h3>
                    <ul>
                        <li><strong>Data Platform Manager</strong></li>
                        <li><strong>Data Engineering Manager</strong></li>
                        <li><strong>Head of Data</strong></li>
                        <li><strong>Data Manager</strong></li>
                        <li><strong>Data Architecture Manager</strong></li>
                        <li><strong>DataOps Manager</strong></li>
                        <li><strong>Data Architect</strong></li>
                        <li><strong>Senior Data Engineer</strong></li>
                        <li><strong>Data Strategy Manager</strong></li>
                        <li><strong>Analytics Manager</strong></li>
                    </ul>
                </div>
                <div class="card">
                    <h3>Setores de Interesse</h3>
                    <ul>
                        <li><strong>Tecnologia</strong></li>
                        <li><strong>Fintech</strong></li>
                        <li><strong>E-commerce</strong></li>
                        <li><strong>Varejo</strong></li>
                        <li><strong>Consultoria</strong></li>
                        <li><strong>Startups</strong></li>
                        <li><strong>Bancos</strong></li>
                        <li><strong>Seguros</strong></li>
                        <li><strong>Telecomunicações</strong></li>
                        <li><strong>Indústria</strong></li>
                    </ul>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
    <footer class="footer">
        <div class="container">
            <p>&copy; 2025 Rodrigo Santili Sgarioni. Todos os direitos reservados.</p>
            <div class="social-links">
                <a href="https://github.com/rodrigosantili" target="_blank">
                    <i class="fab fa-github"></i>
                </a>
                <a href="https://www.linkedin.com/in/rodrigo-santili-sgarioni-48004330" target="_blank">
                    <i class="fab fa-linkedin"></i>
                </a>
                <a href="mailto:rssgarioni@gmail.com">
                    <i class="fas fa-envelope"></i>
                </a>
            </div>
        </div>
    </footer>

    <!-- JavaScript -->
    <script src="assets/js/main.js"></script>
    
    <!-- Schema.org structured data -->
    <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "Person",
      "name": "Rodrigo Santili Sgarioni",
      "jobTitle": "Data Platform Manager",
      "description": "Executivo de Dados com mais de 15 anos de experiência liderando plataformas analíticas e times técnicos.",
      "url": "https://rodrigosantili.github.io",
      "sameAs": [
        "https://www.linkedin.com/in/rodrigo-santili-sgarioni-48004330",
        "https://github.com/rodrigosantili"
      ],
      "knowsAbout": [
        "Data Engineering",
        "Data Architecture", 
        "Cloud Platforms",
        "Machine Learning",
        "DataOps"
      ],
      "worksFor": {
        "@type": "Organization",
        "name": "V8.TECH"
      }
    }
    </script>
</body>
</html> 